<?xml version='1.0' encoding='UTF-8'?>
<document>
  <properties>
    <title>Settings for crawling Web site</title>
    <author>Shinsuke Sugaya</author>
  </properties>
  <body><p style="font-weight:bold;color:red;">This page is generated by Machine Translation from Japanese.</p>
    <section name='Overview'>
      <p>Describes the settings here, using Web crawling.</p>
      <p>Recommends that if you want to index document number 100000 over in Fess crawl settings for one to several tens of thousands of these. One crawl setting a target number 100000 from the indexed performance degrades.</p>
    </section>
    <section name='How to set up'>
      <subsection name='How to display'>
        <p>In Administrator account after logging in, click menu Web.</p>
        <img alt='Web crawl settings' sizeinfo='height=23cm' src='/images/ja/8.0/admin/webCrawlingConfig-1.png'/>
      </subsection>
    </section>
    <section name='Setting item'>
      <subsection name='Setting name'>
        <p>Is the name that appears on the list page.</p>
      </subsection>
      <subsection name='Specify a URL'>
        <p>You can specify multiple URLs. http: or https: in the specify starting. For example,</p>
        <source><![CDATA[
http://localhost/
http://localhost:8080/
]]></source>
        <p>The so determines.</p>
      </subsection>
      <subsection name='URL filtering'>
        <p>By specifying regular expressions you can exclude the crawl and search for specific URL pattern.</p>
        <table class='table table-striped table-bordered table-condensed' columninfo='lp{10cm}'>
<caption>URL filtering contents list</caption>
<tbody>
<tr>
<th>URL to crawl</th>
<td>Crawl the URL for the specified regular expression.</td>
</tr>
<tr>
<th>Excluded from the crawl URL</th>
<td>The URL for the specified regular expression does not crawl. The URL to crawl, even WINS here.</td>
</tr>
<tr>
<th>To search for URL</th>
<td>The URL for the specified regular expression search. Even if specified and the URL to the search excluded WINS here.</td>
</tr>
<tr>
<th>To exclude from the search URL</th>
<td>URL for the specified regular expression search. Unable to search all links since they exclude from being crawled and crawled when the search and not just some.</td>
</tr>
</tbody>
</table>
        <p>For example, http: URL to crawl if not crawl //localhost/ less than the</p>
        <source><![CDATA[
http://localhost/.*
]]></source>
        <p>Also be excluded if the extension of png want to exclude from the URL</p>
        <source><![CDATA[
.*\.png$
]]></source>
        <p>It specifies. It is possible to specify multiple in the line for.</p>
      </subsection>
      <subsection name='Setting parameters'>
        <p>You can specify the crawl configuration information.</p>
      </subsection>
      <subsection name='Depth'>
        <p>That will follow the links contained in the document in the crawl order can specify the tracing depth.</p>
      </subsection>
      <subsection name='Maximum access'>
        <p>You can specify the number of documents to retrieve crawl. If you do not specify people per 100,000.</p>
      </subsection>
      <subsection name='User agent'>
        <p>You can specify the user agent to use when crawling.</p>
      </subsection>
      <subsection name='Number of threads'>
        <p>Specifies the number of threads you want to crawl. Value of 5 in 5 threads crawling the website at the same time.</p>
      </subsection>
      <subsection name='Interval'>
        <p>Is the interval (in milliseconds) to crawl documents. 5000 when one thread is 5 seconds at intervals Gets the document.</p>
        <p>Number of threads, 5 pieces, will be to go to and get the 5 documents per second between when 1000 millisecond interval,. Set the adequate value when crawling a website to the Web server, the load would not load.</p>
      </subsection>
      <subsection name='Boost value'>
        <p>You can search URL in this crawl setting to weight. Available in the search results on other than you want to. The standard is 1. Priority higher values, will be displayed at the top of the search results. If you want to see results other than absolutely in favor, including 10,000 sufficiently large value.</p>
        <p>Values that can be specified is an integer greater than 0. This value is used as the boost value when adding documents to Solr.</p>
      </subsection>
      <subsection name='Browser type'>
        <p>Register the browser type was selected as the crawled documents. Even if you select only the PC search on your mobile device not appear in results. If you want to see only specific mobile devices also available.</p>
      </subsection>
      <subsection name='Roll'>
        <p>You can control only when a particular user role can appear in search results. You must roll a set before you. For example, available by the user in the system requires a login, such as portal servers, search results out if you want.</p>
      </subsection>
      <subsection name='Label'>
        <p>You can label with search results. Search on each label, such as enable, in the search screen, specify the label.</p>
      </subsection>
      <subsection name='State'>
        <p>Crawl crawl time, is set to enable. If you want to avoid crawling temporarily available.</p>
      </subsection>
    </section>
    <section name='Other'>
      <subsection name='Sitemap'>
        <p>Fess and crawls sitemap file, as defined in the URL to crawl. Sitemap<a href='http://www.sitemaps.org/'>http://www.sitemaps.org/</a> Of the specification. Available formats are XML Sitemaps and XML Sitemaps Index the text (URL line written in).</p>
        <p>Site map the specified URL. Sitemap is a XML files and XML files for text, when crawling that URL of ordinary or cannot distinguish between what a sitemap. Because the file name is sitemap.*.xml, sitemap.*.gz, sitemap.*txt in the default URL as a Sitemap handles (in webapps/fess/WEB-INF/classes/s2robot_rule.dicon can be customized).</p>
        <p>Crawls sitemap file to crawl the HTML file links will crawl the following URL in the next crawl.</p>
      </subsection>
    </section>
  </body>
</document>
