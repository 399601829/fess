<?xml version='1.0' encoding='UTF-8'?>
<document>
  <properties>
    <title>Settings for file system crawling</title>
    <author>Shinsuke Sugaya</author>
  </properties>
  <body><p style="font-weight:bold;color:red;">This page is generated by Machine Translation from Japanese.</p>
    <section name='Overview'>
      <p>Describes the settings for crawl here, using file system.</p>
      <p>Recommends that if you want to index document number 100000 over in Fess crawl settings for one to several tens of thousands of these. One crawl setting a target number 100000 from the indexed performance degrades.</p>
    </section>
    <section name='How to set up'>
      <subsection name='How to display'>
        <p>In Administrator account after logging in, click menu file.</p>
        <img alt='Setting file system Crawl' sizeinfo='height=23cm' src='/images/en/9.2/admin/fileCrawlingConfig-1.png'/>
      </subsection>
    </section>
    <section name='Setting item'>
      <subsection name='Setting name'>
        <p>Is the name that appears on the list page.</p>
      </subsection>
      <subsection name='Specifying a path'>
        <p>You can specify multiple paths. file: or smb: in the specify starting. For example,</p>
        <source><![CDATA[
file:/home/taro/
file:/home/documents/
smb://host1/share/
]]></source>
        <p>The so determines. Patrolling below the specified directory.</p>
        <p>So there is need to write URI if the Windows environment path that c:\Documents\taro in file/c: /Documents/taro and specify.</p>
        <p>Windows shared folder, for example, if you want to crawl to host1 share folder crawl settings for smb: (last / to) the //host1/share/. If authentication is in the shared folder on the file system authentication screen set authentication information.</p>
      </subsection>
      <subsection name='Path filtering'>
        <p>By specifying regular expressions you can exclude the crawl and search for given path pattern.</p>
        <table class='table table-striped table-bordered table-condensed' columninfo='lp{10cm}'>
<caption>IP rings contents list</caption>
<tbody>
<tr>
<th>Path to crawl</th>
<td>Crawl the path for the specified regular expression.</td>
</tr>
<tr>
<th>The path to exclude from being crawled</th>
<td>The path for the specified regular expression does not crawl. The path you want to crawl, even WINS here.</td>
</tr>
<tr>
<th>Path to be searched</th>
<td>The path for the specified regular expression search. Even if specified path to find excluded and WINS here.</td>
</tr>
<tr>
<th>Path to exclude from searches</th>
<td>Not search the path for the specified regular expression. Unable to search all links since they exclude from being crawled and crawled when the search and not just some.</td>
</tr>
</tbody>
</table>
        <p>For example, the path to target if you don&apos;t crawl less than/home /</p>
        <source><![CDATA[
file:/home/.*
]]></source>
        <p>Also the path to exclude if extension of png want to exclude from</p>
        <source><![CDATA[
.*\.png$
]]></source>
        <p>It specifies. It is possible to specify multiple line breaks in.</p>
        <p>How to specify the URI handling java.io.File: Looks like:</p>
        <source><![CDATA[
/home/taro -> file:/home/taro
c:\memo.txt -> file:/c:/memo.txt
\\server\memo.txt -> file:////server/memo.txt
]]></source>
      </subsection>
      <subsection name='Setting parameters'>
        <p>You can specify the crawl configuration information.</p>
      </subsection>
      <subsection name='Depth'>
        <p>Specify the depth of a directory hierarchy.</p>
      </subsection>
      <subsection name='Maximum access'>
        <p>You can specify the number of documents to retrieve crawl.</p>
      </subsection>
      <subsection name='Number of threads'>
        <p>Specifies the number of threads you want to crawl. Value of 5 in 5 threads crawling the website at the same time.</p>
      </subsection>
      <subsection name='Interval'>
        <p>Is the time interval to crawl documents. 5000 when one thread is 5 seconds at intervals Gets the document.</p>
        <p>Number of threads, 5 pieces, will be to go to and get the 5 documents per second between when 1000 millisecond interval,.</p>
      </subsection>
      <subsection name='Boost value'>
        <p>You can search URL in this crawl setting to weight. Available in the search results on other than you want to. The standard is 1. Priority higher values, will be displayed at the top of the search results. If you want to see results other than absolutely in favor, including 10,000 sufficiently large value.</p>
        <p>Values that can be specified is an integer greater than 0. This value is used as the boost value when adding documents to Solr.</p>
      </subsection>
      <subsection name='Roll'>
        <p>You can control only when a particular user role can appear in search results. You must roll a set before you. For example, available by the user in the system requires a login, such as portal servers, search results out if you want.</p>
      </subsection>
      <subsection name='Label'>
        <p>You can label with search results. Search on each label, such as enable, in the search screen, specify the label.</p>
      </subsection>
      <subsection name='State'>
        <p>Crawl crawl time, is set to enable. If you want to avoid crawling temporarily available.</p>
      </subsection>
    </section>
  </body>
</document>
