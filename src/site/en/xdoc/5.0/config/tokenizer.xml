<?xml version='1.0' encoding='UTF-8'?>
<document>
  <properties>
    <title>Settings for the index string extraction</title>
    <author>Sone, Takaaki</author>
  </properties>
  <body>

    <section name='About the index string extraction'>
      <p>You must isolate the document in order to register as the index when creating indexes for the search.</p>
      <p>Tokenizer is used for this.</p>
      <p>Basically, carved by the tokenizer units smaller than go find no hits.</p>
      <p>For example, statements of living in Tokyo, Japan. Was split by the tokenizer now, this statement is in Tokyo, living and so on. In this case, in Tokyo, Word search, you will get hit. However, when performing a search with the word &apos;Kyoto&apos; will not be hit.</p>
      <p>For selection of the tokenizer is important.</p>
      <p>You can change the tokenizer by setting the schema.xml analyzer part is if the Fess in the default CJKTokenizer used.</p>
    </section>

    <subsection name='About CJKTokenizer'>
      <p>Such as CJKTokenizer Japan Japanese multibyte string against bi-gram, in other words two characters create index. In this case, can&apos;t find one letter words.</p>
    </subsection>

    <subsection name='About StandardTokenizer'>
      <p>StandardTokenizer creates index uni-gram, in other words one by one for the Japan language of multibyte-character strings. Therefore, the less search leakage. Also, with StandardTokenizer can&apos;t CJKTokenizer the search query letter to search to.</p>
      <p>The following example to change schema.xml so analyzer parts, you can use the StandardTokenizer.</p>
      <source><![CDATA[
  :
  <types>
    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
      <analyzer>
        <tokenizer class="solr.StandardTokenizerFactory"/>
  :
]]></source>
    </subsection>

  </body>
</document>
